{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN with attribute\n",
    "## Architecture:\n",
    "* <b>image size: (H, W): from (218, 178) to (32, 32)</b>\n",
    "* <b>Generator:</b> 1 FC + 4 deconv layer <br>\n",
    "    [**(data)**+**(attr)**] \n",
    "    -> [FC] -> flatten -> BN1 -> lReLU1  <br>\n",
    "    ->[Decv2] -> BN2 -> lReLU2 <br>\n",
    "    ->[Decv3] -> BN3 -> lReLU3 <br>\n",
    "    ->[Decv4] -> sigmoid<br>\n",
    "* <b>Discriminator:</b>4 conv layer + 1 FC layer <br>\n",
    "    [**(data)**] \n",
    "    ->[Conv1] -> lReLU1 -> <br>\n",
    "    ->[Conv2] -> BN2 -> lReLU2 <br>\n",
    "    ->[Conv3] -> BN3 -> lReLU3 <br>\n",
    "    ->flatten + **(attr)** -> [FC]<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.misc\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "mb_size = 16\n",
    "num_of_img = 20000\n",
    "Z_dim = 100  # noize dim\n",
    "X_dim = 116412 # 178 * 218 * 3\n",
    "y_dim = 23 # total attr dim\n",
    "h_dim = 128 # last FC hidden layer\n",
    "\n",
    "H_ = 32 \n",
    "W_ = 32 \n",
    "attr_dim = 1 # desired sample attr dim\n",
    "\n",
    "### det directory\n",
    "OUTPUT_DIR = 'output_DCGAN_attr/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "* helper function for risizee image\n",
    "* load data & attr\n",
    "* choose choose specific features for observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_crop(x, crop_h, crop_w,\n",
    "                resize_h=64, resize_w=64):\n",
    "    if crop_w is None:\n",
    "        crop_w = crop_h\n",
    "    h, w = x.shape[:2]\n",
    "    j = int(round((h - crop_h)/2.))\n",
    "    i = int(round((w - crop_w)/2.))\n",
    "    return scipy.misc.imresize(\n",
    "        x[j:j+crop_h, i:i+crop_w], [resize_h, resize_w])\n",
    "\n",
    "def transform(image, input_height, input_width, \n",
    "              resize_height=64, resize_width=64, crop=True):\n",
    "    if crop:\n",
    "        cropped_image = center_crop(\n",
    "          image, input_height, input_width, \n",
    "          resize_height, resize_width)\n",
    "    else:\n",
    "        cropped_image = scipy.misc.imresize(image, [resize_height, resize_width])\n",
    "#     return np.array(cropped_image)/127.5 - 1.\n",
    "    return np.array(cropped_image)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "#     cols = [\"Arched_Eyebrows\", \"Bags_Under_Eyes\", \"Bangs\", \"Big_Lips\", \"Big_Nose\", \"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\",\n",
    "#        \"Bushy_Eyebrows\",\"Eyeglasses\",\"Heavy_Makeup\",\"High_Cheekbones\",\"Male\", \"Mouth_Slightly_Open\",\"Narrow_Eyes\",\n",
    "#        \"No_Beard\",\"Oval_Face\",\"Pointy_Nose\",\"Smiling\",\"Straight_Hair\",\"Wavy_Hair\",\"Wearing_Hat\",\"Young\"]\n",
    "    cols = [\"Male\", \"Smiling\"]\n",
    "\n",
    "    attr = pd.read_csv('data/list_attr_celeba.csv', delim_whitespace=True, skiprows=1, usecols=cols)\n",
    "\n",
    "    attr = attr.values[:num_of_img]\n",
    "    print(\"shape of attr: {}\".format(attr.shape))\n",
    "   \n",
    "    X = []\n",
    "\n",
    "    for i in range(num_of_img):\n",
    "        X_ = scipy.misc.imread('data/img_align_celeba/{:06d}.jpg'.format(i + 1))\n",
    "        X_ = transform(X_, 218, 178, H_, W_, True)\n",
    "        X_ = X_.reshape(H_ * W_ * 3)\n",
    "        #X_ = np.concatenate([X_, attr[i]])\n",
    "        X.append(X_)\n",
    "\n",
    "    X = np.array(X)\n",
    "    \n",
    "   \n",
    "    #print\n",
    "    print(\"shape of one image: {}\".format(X[0].shape))\n",
    "    print(\"min of one image: {}\".format(np.amin(X[0])))\n",
    "    print(\"max of one image: {}\".format(np.amax(X[0])))\n",
    "    print(\"shape of X: {}\".format(X.shape))\n",
    "    \n",
    "    return X, attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]]\n",
      "shape of attr: (20000, 2)\n",
      "shape of one image: (3072,)\n",
      "min of one image: 0.0078431372549\n",
      "max of one image: 0.996078431373\n",
      "shape of X: (20000, 3072)\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "###           choose specific features for observation            ###\n",
    "#####################################################################\n",
    "# features = [(\"Arched_Eyebrows\", -1), (\"Bags_Under_Eyes\", -1), (\"Bangs\", 1), (\"Big_Lips\", -1), (\"Big_Nose\", -1),\n",
    "#             (\"Black_Hair\", -1), (\"Blond_Hair\", 1), (\"Brown_Hair\", -1), (\"Bushy_Eyebrows\", -1), (\"Eyeglasses\", -1),\n",
    "#             (\"Heavy_Makeup\", -1), (\"High_Cheekbones\", 1), (\"Male\", 1), (\"Mouth_Slightly_Open\", -1), (\"Narrow_Eyes\", 1),\n",
    "#             (\"No_Beard\", -1), (\"Oval_Face\", 1), (\"Pointy_Nose\", -1), (\"Smiling\", 1), \n",
    "#             (\"Straight_Hair\", 1), (\"Wavy_Hair\", -1), (\"Wearing_Hat\", -1), (\"Young\", 1)]\n",
    "# features = map(lambda x: x[1], features)\n",
    "\n",
    "features = [1, 1] # Male, 1 # Smiling, 1\n",
    "\n",
    "# store sample feature\n",
    "sample_features = np.array(features).reshape((-1,2))\n",
    "print(sample_features)\n",
    "#####################################################################\n",
    "###                        Load celeb data                        ###\n",
    "#####################################################################\n",
    "# (1) reshape date (2) select desired attributes\n",
    "celeb_data, attr = load_train_data()\n",
    "celeb_data = celeb_data.reshape((celeb_data.shape[0], H_, W_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of desired_attr: (20000, 2)\n",
      "shape of one image: (32, 32, 3)\n",
      "feature of the image: [0 1]\n",
      "shape of one image: (32, 32, 3)\n",
      "feature of the image: [0 1]\n",
      "shape of one image: (32, 32, 3)\n",
      "feature of the image: [1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10c25cd10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiES5f8BaB4D+Snr0fQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c490fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrdsid7UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d84cb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAG2FJREFUeJztnW2MXGd1x//n3pndnd31++vGMXHe\nUAm0MenWAhEhXgRKEVJAqiKohPIhwqgiUpHohyiVSir1A1QFxIeKyjQRoQJCgCCiKmpJI6SIL4EN\nDU5CaPOC09ixvbbX3p3dndd7Tz/MtbTePOfseF/u2Dz/n2R59jlz7z3zzD33zjz/OeeIqoIQEh/J\noB0ghAwGBj8hkcLgJyRSGPyERAqDn5BIYfATEikMfkIihcFPSKQw+AmJlMpaNhaROwB8A0AK4F9V\n9cve83fu3KkHDhxYyyE3HO8Xj1mWB8fzPDwOAGmaOjZee8n6cuzYMZw9e1b6ee6qg19EUgD/DOAj\nAI4D+JWIPK6qv7W2OXDgAKamplZ7yLegsAN1tT9a7nYz01afmw+ONxZb5jabN42btrHxmmlLEvv9\nE+nrvR0oZf5s/GqYj7KYnJzs+7lrufUcAvCKqr6mqm0AjwC4cw37I4SUyFqCfx+AN5b8fbwYI4Rc\nBWz4l04ROSwiUyIydebMmY0+HCGkT9YS/CcA7F/y97XF2CWo6hFVnVTVyV27dq3hcISQ9WQtwf8r\nADeLyPUiMgTgUwAeXx+3CCEbzapX+1W1KyL3AvhP9KS+h1T1xTXsz7YZa/eadVa5P5vpM+dM2ysv\n/z443m51zW327t5r2m686XrTVhsdMm1X8+I2V+avHNak86vqEwCeWCdfCCElwl+ZEBIpDH5CIoXB\nT0ikMPgJiRQGPyGRsqbV/stFNUezuRi01efq5nYn3jweHD91KjwOAJ1G+DgAUBuyZTTNbSHw/NxC\ncHx4xEnQ2b3FtFXshD8XV8Y0bLmzTSL2PSBxdNFcPDk1nCCVwH7RGWwZMHEkQt7BVgfnjZBIYfAT\nEikMfkIihcFPSKQw+AmJlFJX+2dmZvDDR78XtB17/Zi53YXzF4Lj3WbD3CZrN03bcMVeOd7ilNYa\nHhkJjo/Vhs1tKk07UahWdfzYsce0SWLXDLxwYSY4vuCoKbucYw0N2fOx0A6rHwDQWAjXbti7Z39w\nHADGttkp31KpmjY4CgKx4Z2fkEhh8BMSKQx+QiKFwU9IpDD4CYkUBj8hkVKq1Dc7O4cnnngyaOt2\n7Tp4VuLJUGJfu3K19wcnIeXsnN19Z6QalpRGqrYfb5ywy5X/4pnnTNv4ps2mzVO9Wu1wQtOOzaPm\nNtu2bLN3mNpSX7Npy4djCHc32uVIfbcc+qBp273/JtPmZUixYqAN7/yERAqDn5BIYfATEikMfkIi\nhcFPSKQw+AmJlDVJfSJyDEAdQAagq6qT3vPzXNFo2i22LFIji00zW87L1c5862a2LdPLbwFWSW1B\nachJOHOS8zA+Gs5kBICKIy22WmGp79SQvc3WLbas2HYk2NSo0wcAI0nYlr/4srnNmfmwPAgAH/r4\nX5q2nXveZtrWX+zzmr2tdrvV7nNtrIfO/0FVPbsO+yGElAg/9hMSKWsNfgXwMxF5VkQOr4dDhJBy\nWOvH/ttV9YSI7AbwpIj8TlWfXvqE4qJwGABqNfunooSQclnTnV9VTxT/TwP4CYBDgeccUdVJVZ0c\nGrLLXRFCymXVwS8iYyKy6eJjAB8F8MJ6OUYI2VjW8rF/D4CfSK+NUgXA91T1P7wNVBWdjiGlOYqM\nJTaJ2FqZ19Iqd1pyeY5YHaPaTgJh25EVK861t1O3i2MOVb23LfzaWl07W3Gxdd7em63mIXfmv9lp\nB8dHnIzK0d+fMm0HZ2zpc8fufaZNxNJaPQnQOz+cCXFxjqdhmzp+2Odw/7LhqoNfVV8DcOtqtyeE\nDBZKfYRECoOfkEhh8BMSKQx+QiKFwU9IpJRawFOh6GRhqU8sHQ22xAZHzutmtiSTOzZxpJLEKBia\nJI7vnlzjyF65Mx8NR1u0JM7UKXLZqgyZtk7HlvNabbtXYsW4rWxzZLlr9r/TtO3ceY1py7pelqYx\nH6k9H27+nWPMHFm30bDnql4PF0JdXAhnaALAorG/xUW7R+VyeOcnJFIY/IRECoOfkEhh8BMSKQx+\nQiKl1NX+RMRMSvFWWK1WXnm+usQeb6XXWbg3FYnEWZmvOJkxNaeI3+YR28eK2KvzZgKJ88LaXUcZ\ncVSCoTG7Bdj23TuC43/8Z7eb2/zpofeZtvkFO9Hp3IVZ07ZpLFyfsN0OJx4BQL0+Z9paLXvVfrFh\nr87PzJwzbRdmZ4LjTUchsJJ+FhbsFmrL4Z2fkEhh8BMSKQx+QiKFwU9IpDD4CYkUBj8hkVJuYo8q\nMiOpRsS+DlkilZcM5Ml5XvU2b5+WpDeU2Mcar9hTvG+bXcp812bbNpLaMqalcHqyqDhztesaOxGn\nWhsxbelw+HUPOxLmq787atpamf2ah2u25GiVujvnSG/zTtswOMlY6sxxq23XUGwZkp6XnGadi91u\n/+3weOcnJFIY/IRECoOfkEhh8BMSKQx+QiKFwU9IpKwo9YnIQwA+DmBaVd9VjG0H8AMABwAcA3CX\nqto9n5ZiKCWqtkySG7XRjC5HKHy8XBcKoyOJGQf0MgFHnKy4zTU7O29syMmmSxy5yTIktixXGx83\nbTfdfJNpazlvwNxiWL6adTLm5pv2KdT1BNqkapo6xrmz4GQJto1WY4BTTxLwa0oamakAoNb57ZyL\nVlafJ+kup587/7cB3LFs7D4AT6nqzQCeKv4mhFxFrBj8qvo0gOUJx3cCeLh4/DCAT6yzX4SQDWa1\n3/n3qOrJ4vEp9Dr2EkKuIta84Ke9kjnmlx0ROSwiUyIy5VVPIYSUy2qD/7SITABA8f+09URVPaKq\nk6o6OTTklZ8ihJTJaoP/cQB3F4/vBvDT9XGHEFIW/Uh93wfwAQA7ReQ4gC8B+DKAR0XkHgCvA7ir\n/0OGvyF4BTetbdzsPNcF+1jiFNxU41qZONLbiJPVV6va115PPvTmyrJUjFZjADBctaWyc2ft7DcZ\ntSXCs7PhtlELLTvrrNG0C1a2O7ZU1rFS92Bn9a22+KsnFOeONJc52XZWNqDnhvW6fN8vZcXgV9VP\nG6YP930UQsgVB3/hR0ikMPgJiRQGPyGRwuAnJFIY/IRESqkFPAFFYsghnkQhRtFET1rxUvfEMaoj\nG1kpXcOO1Ldt1P5h00jF1vO87DFLcnTxZKjMltGqqX2sTWO21HdqNpw1d3rGzurT3OkZ6Nk8ecuw\neZuII4tKYoeMdw7nTgaktc/UyVasGjYROxt0ObzzExIpDH5CIoXBT0ikMPgJiRQGPyGRwuAnJFLK\nlfoUQB6WlVz5zcrMuowMpqV4V7yK0zOwZkh6ezcNm9tMbLV77tWqtiyjFVsi9NRIK1ut48xVfaFu\n2kZmz5i2RGyJ0CpO2s3snnWryXwDVif1eVpqKrbEVvFsFbtnoNejMK2GwzAR+xywJL007T+keecn\nJFIY/IRECoOfkEhh8BMSKQx+QiKl9MSeroZXdNPcXn3NjIp81jgAM4EI8JNmUsdYq4Ztu7fYrbDG\narbNSxKx172BZitcHw8A2o1wHbxm095G4NTHa8yatqxrl2I/Yxwud1ph5V07eSdxVJiK2POYGG3P\nKkO2QpNWbVsltdWbSmqvzieprRLYiUS2QpBll69ivMWnvp9JCPmDgsFPSKQw+AmJFAY/IZHC4Cck\nUhj8hERKP+26HgLwcQDTqvquYuwBAJ8FcDHr435VfWKlfdWqKW7dsyVom5ldNLebXgwngyyqfe3y\nkl88ibBi1AsEgG2bx8LjW+1adolTUi1zWoO1nNZV3bYtzVkKUObM1ciwI19VbalyqGonsmAxLFZW\nU3tCqsP26Zg6UlnVSYKyJD1P6lOnDp7m9jyqM8finAjWGZcZSXAA0OqEtdTLadfVz53/2wDuCIx/\nXVUPFv9WDHxCyJXFisGvqk8DmCnBF0JIiazlO/+9InJURB4SkW3r5hEhpBRWG/zfBHAjgIMATgL4\nqvVEETksIlMiMtVo2j/tJISUy6qCX1VPq2qmqjmAbwE45Dz3iKpOqupkbcRemCGElMuqgl9EJpb8\n+UkAL6yPO4SQsuhH6vs+gA8A2CkixwF8CcAHROQgeirFMQCf6+dgo9UUt06ElwemnTp4w6cvBMfP\nNG1ZY7FtSyuJ2DlzW0btKblu1/bg+Oiw/YnGa//Vadl+ZC3ntRkyGgA02uFsxsRpu1V15Dzv/jA3\nO2/adu84EBxvj9rZlm2njqOkto+JI6OlhrSojtzbzZzWYF4bNUfq81qsWftsORmQzWZYGrdqOIZY\nMfhV9dOB4Qf7PgIh5IqEv/AjJFIY/IRECoOfkEhh8BMSKQx+QiKl1AKeuSoaRvHJ0Yp9HTqwY1Nw\nfKi+YG4zU7flsGHnWG9/217TtneLkcUmq2slVXEy3MYcyXHIkRZb3bAv4khbw0a7KAAYrtg+5m1H\nEjPem/3X3GBuc6xuZ3a2c9uPIadYa4awzZPEMuc98zL+xGuV5WyXdcLnartptzZrLITn93KkPt75\nCYkUBj8hkcLgJyRSGPyERAqDn5BIYfATEimlSn2qiiwLSxFp1S4iuWtHWNrastWWvM7P27JRzTnW\ntnGn3xrC0lbm9gW0bYmXIeZkuDl1LpEa2Xudji3LpYYcBgCS2RJV18kU7MydDo5Xa/Y2m2u7TNv0\nol3Msu308Us0PMnq9MGD00Mx8Yp7GscCgNw47wGg3Qz3Q1yonzW3aTbCGZWa2+/zcnjnJyRSGPyE\nRAqDn5BIYfATEikMfkIipdTV/iRJUBsPt7xKnBXbTjecxDDirDZPbLZbaHktjVI45cWNVk3eFTRz\navglRhIOsELbJaeQXGLt0lEkckdZ8FQHbYeTtACgZWzXPmfX4mvtsts/SO7UGfTeAMP91DnfPBzx\nBpmTVNM1au4BQGMhXKOyuRgeB4CsG17VV+d9Xg7v/IRECoOfkEhh8BMSKQx+QiKFwU9IpDD4CYmU\nftp17QfwHQB70BNOjqjqN0RkO4AfADiAXsuuu1T1vLevLFfMLTaCtq3jtiuSh2ucOUoZJHGSPZz2\nTmok7/SM/csoF0kdyc5Tm7xEkCyz95kbtqRStQ/m0GiE3y8AyFK7xZpu3x/eZthO3ml27ISr1GmF\nBSehBhp+P3PvvfRq+Bn7A4BO264bubhYN22NhbngeNaxa/iJ6aIjES+jnzt/F8AXVfUWAO8B8HkR\nuQXAfQCeUtWbATxV/E0IuUpYMfhV9aSq/rp4XAfwEoB9AO4E8HDxtIcBfGKjnCSErD+X9Z1fRA4A\neDeAZwDsUdWThekUel8LCCFXCX0Hv4iMA/gxgC+o6iVfUrT3W9Tglw0ROSwiUyIyNd+wv8MQQsql\nr+AXkSp6gf9dVX2sGD4tIhOFfQLAdGhbVT2iqpOqOjlesxeICCHlsmLwi4gAeBDAS6r6tSWmxwHc\nXTy+G8BP1989QshG0U9W3/sAfAbA8yLyXDF2P4AvA3hURO4B8DqAu1baUZIAo8Ph64162W9JWKZS\nQwLsGT1PHPnN9SMsKSViS03iFOrzpEp19ul0rkJmSFGV1K5NmHs18JwPa/tufIdpuzA8ERw/M2vX\n4qt49yKvJZpTg1ANydST+ryMyiyz/W81vMy9cJ0+AMi74a/DVaedW2K0X/Pasi1nxeBX1V8A5h4/\n3PeRCCFXFPyFHyGRwuAnJFIY/IRECoOfkEhh8BMSKeUW8BRgyJD64GSxWUUkPVkj97LpPGnOUUos\nm9UiC4CbIebanNfmSVGtVrgAaeboitWRcFFVAKgN27Z63S7gOdsKy165d8qpLd16hURzp0VV23jZ\nVtu4lfaXd+0sx4X5c6atPm+33kqNTNKRqi31VStGMVmvB9zy5/b9TELIHxQMfkIihcFPSKQw+AmJ\nFAY/IZHC4CckUkqV+hR2L7HEy7Sz1AtPl/N6zDlSmZftlVjXSi8Dz+nf5klK3nXZz0gLj3c6djba\n7j12j7wRR+rLx+ztTrfCc9LNbT/cwpn2Vug689Fsh+e4YYwDgPOWQTt2L8eF+XBPSQCo1+2svgTh\nOcmc+hfjtXDvQrfH41uOSwiJEgY/IZHC4CckUhj8hEQKg5+QSCl1tR+AuWwrTh25ipHEIM4acKdj\nJ4m4K/BOQk1m1JHTrr2CnWf2qrK6y8q2qeK0Its8Hl6dl8R+qxsLdiupxHlfdu6wV/uzN8MJMAtN\nOzFGvVp8zvvSceouttrh96a1ytX+vG37P79gr/Z7bc/yLHyutpt24lSnGa7759UYXA7v/IRECoOf\nkEhh8BMSKQx+QiKFwU9IpDD4CYmUFaU+EdkP4DvoteBWAEdU9Rsi8gCAzwI4Uzz1flV9YsUjGoqN\nl5BgyU1em6zUaXXkSX2eH12jDp44raQ8OdKTN73XlogjcXbDEpY6kmOnY8tQ51uOtFXbbtrOzYdb\nrNUbtnzVdfqQ5V6ik1fv0KiPl3oJXI7NaocGAJkzx3nuJKFp+HW3HTlyPgvPY5b1n9jTj87fBfBF\nVf21iGwC8KyIPFnYvq6q/9T30QghVwz99Oo7CeBk8bguIi8B2LfRjhFCNpbL+s4vIgcAvBvAM8XQ\nvSJyVEQeEhH7516EkCuOvoNfRMYB/BjAF1R1DsA3AdwI4CB6nwy+amx3WESmRGSqvhj+SSIhpHz6\nCn4RqaIX+N9V1ccAQFVPq2qmvdI83wJwKLStqh5R1UlVndw06jR7J4SUyorBL732Ng8CeElVv7Zk\nfGLJ0z4J4IX1d48QslH0s9r/PgCfAfC8iDxXjN0P4NMichA9+e8YgM+tuCcBkBqSh5NJZSk5qZPd\nliRhqQmwW1oBtlQGwKwx511BK4kjYTr+iyPneVi1EDNPanJkxb033GTaZobtZZ5Tx6eD4/Mt+3V5\nGWmqto8Vp63VSDV8vFrFkWCNmnoAkOT2uaOO/7nTHsySdSsV+xxOjTjyWtG9Zf8rPUFVf4Fw+K2s\n6RNCrlj4Cz9CIoXBT0ikMPgJiRQGPyGRwuAnJFJKLeApEFPecq9ChsTmZVF1naKaXqHISsVrvWX5\n4bXkcqQ+R77y5sNTAcV4S/0MQudgXuHMti17zS0sBsfnu/YPvXJHYkudbMuhrvPajHOk4kh9Kqs7\nrzzp1rNV0rAv42PhllwAMFQJy5tp2v/9nHd+QiKFwU9IpDD4CYkUBj8hkcLgJyRSGPyERErpvfpS\nQ95yC2caUlq3a/fj86hW7Wwpt/+fUcCz0bGloZbTI2/Lll2mrT4XlsoAIOvYRTAlt6So1fUnnHvj\npGk7lds9/tpto6+hI4uKOH3mnPPD7eNn7HI+cbLsnFuio85CRjaZtjFDmgOAioYl09qwfZ5Wrf6V\njqS7HN75CYkUBj8hkcLgJyRSGPyERAqDn5BIYfATEiklZ/X1MvtMo4HVW89puecWP8wMyQ4Ami1b\nRptvhPsOLLac3m6je0zbtTe817RNv/aqaZs5Gy6OCQCJIWOKk+3VdYqWzl6wJbYLHbsPgxp996pO\nH7zU66HopDJKYstomZGyqI6e58l5CexjDVeHTFvFkZcTo1eiW3PVKlBLqY8QshIMfkIihcFPSKQw\n+AmJFAY/IZGy4mq/iIwAeBrAcPH8H6nql0TkegCPANgB4FkAn1E1MhQKVIEsC6/aqjp10zrhVWBj\nVz1by04SaSzaK/oLTTtZqGmsYNcze5V3y8TbTJuM24k9i/KaaZszLUDWCfuyeXiHuc3WrTXT9s7r\nrjNtWrXr8Z07ezY4fub0aXOb8/V509Zx6jVmjoLgJRLZOElEjlIkXaeVlxMarXb4XLWUit4Ow/dt\nL0FuOf3c+VsAPqSqt6LXjvsOEXkPgK8A+Lqq3gTgPIB7+j4qIWTgrBj82uPiJbla/FMAHwLwo2L8\nYQCf2BAPCSEbQl/f+UUkLTr0TgN4EsCrAC6o6sXPK8cB7NsYFwkhG0Ffwa+qmaoeBHAtgEMA/qjf\nA4jIYRGZEpGpuvNdmxBSLpe12q+qFwD8HMB7AWwVkYsLhtcCOGFsc0RVJ1V1ctOo3YSAEFIuKwa/\niOwSka3F4xqAjwB4Cb2LwF8UT7sbwE83yklCyPrTT2LPBICHRSRF72LxqKr+u4j8FsAjIvIPAP4b\nwIMr7ShXxUI7LNlUnZpquaHpdTq2LNc2jgMATUM6BIB2OmbaFiScTNGs2JLX9s1bTFs3c/yvO62w\npmfs7bphiS3dYb/mqm43baeOBz/QAQDe/o53mbbrD94WHH/99f8zt3nz9Jumzau76Nmslm7Npv0V\ndNqTI2fspKp2c9a0Afb7mRuZRN3Mvje3DHnTaw+3nBWDX1WPAnh3YPw19L7/E0KuQvgLP0IihcFP\nSKQw+AmJFAY/IZHC4CckUuRysoDWfDCRMwBeL/7cCSCsS5UL/bgU+nEpV5sf16mqnS66hFKD/5ID\ni0yp6uRADk4/6Af94Md+QmKFwU9IpAwy+I8M8NhLoR+XQj8u5Q/Wj4F95yeEDBZ+7CckUgYS/CJy\nh4j8j4i8IiL3DcKHwo9jIvK8iDwnIlMlHvchEZkWkReWjG0XkSdF5OXi/20D8uMBETlRzMlzIvKx\nEvzYLyI/F5HfisiLIvLXxXipc+L4UeqciMiIiPxSRH5T+PH3xfj1IvJMETc/EBG7cmw/qGqp/wCk\n6JUBuwHAEIDfALilbD8KX44B2DmA474fwG0AXlgy9o8A7ise3wfgKwPy4wEAf1PyfEwAuK14vAnA\n/wK4pew5cfwodU7Q61w5XjyuAngGwHsAPArgU8X4vwD4q7UcZxB3/kMAXlHV17RXz/gRAHcOwI+B\noapPA1ielH8neoVQgZIKohp+lI6qnlTVXxeP6+gVi9mHkufE8aNUtMeGF80dRPDvA/DGkr8HWfxT\nAfxMRJ4VkcMD8uEie1T1ZPH4FAC7ve/Gc6+IHC2+Fmz414+liMgB9OpHPIMBzskyP4CS56SMormx\nL/jdrqq3AfhzAJ8XkfcP2iGgd+WH1zliY/kmgBvR69FwEsBXyzqwiIwD+DGAL6jqJb1JypyTgB+l\nz4muoWhuvwwi+E8A2L/kb7P450ajqieK/6cB/ASDrUx0WkQmAKD4364XtYGo6unixMsBfAslzYmI\nVNELuO+q6mPFcOlzEvJjUHNSHPuyi+b2yyCC/1cAbi5WLocAfArA42U7ISJjIrLp4mMAHwXwgr/V\nhvI4eoVQgQEWRL0YbAWfRAlzIiKCXg3Il1T1a0tMpc6J5UfZc1Ja0dyyVjCXrWZ+DL2V1FcB/O2A\nfLgBPaXhNwBeLNMPAN9H7+NjB73vbveg1/PwKQAvA/gvANsH5Me/AXgewFH0gm+iBD9uR+8j/VEA\nzxX/Plb2nDh+lDonAP4EvaK4R9G70PzdknP2lwBeAfBDAMNrOQ5/4UdIpMS+4EdItDD4CYkUBj8h\nkcLgJyRSGPyERAqDn5BIYfATEikMfkIi5f8BU3kYX5ZBtDkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a5e0190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desired_attr = attr # index 12: Male, index 18: Smiling\n",
    "print \"shape of desired_attr: {}\".format(desired_attr.shape)\n",
    "\n",
    "# store training data and attr\n",
    "train_samples = celeb_data, desired_attr.reshape((-1, 2))\n",
    "\n",
    "\n",
    "# check training data and feature\n",
    "print(\"shape of one image: {}\".format(train_samples[0][0].shape))\n",
    "print(\"feature of the image: {}\".format(train_samples[1][0]))\n",
    "fig = plt.figure()\n",
    "plt.imshow(train_samples[0][0])\n",
    "\n",
    "print(\"shape of one image: {}\".format(train_samples[0][1].shape))\n",
    "print(\"feature of the image: {}\".format(train_samples[1][1]))\n",
    "fig = plt.figure()   \n",
    "plt.imshow(train_samples[0][1])\n",
    "print(\"shape of one image: {}\".format(train_samples[0][2].shape))\n",
    "print(\"feature of the image: {}\".format(train_samples[1][2]))\n",
    "fig = plt.figure()   \n",
    "plt.imshow(train_samples[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement GAN\n",
    "\n",
    "* (1) define layer function\n",
    "* (2) DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viz_grid(Xs, padding):\n",
    "    N, H, W, C = Xs.shape\n",
    "    grid_size = int(math.ceil(math.sqrt(N)))\n",
    "    grid_height = H * grid_size + padding * (grid_size + 1)\n",
    "    grid_width = W * grid_size + padding * (grid_size + 1)\n",
    "    grid = np.zeros((grid_height, grid_width, C))\n",
    "    next_idx = 0\n",
    "    y0, y1 = padding, H + padding\n",
    "    for y in range(grid_size):\n",
    "        x0, x1 = padding, W + padding\n",
    "        for x in range(grid_size):\n",
    "            if next_idx < N:\n",
    "                img = Xs[next_idx]\n",
    "                grid[y0:y1, x0:x1] = img\n",
    "                next_idx += 1\n",
    "            x0 += W + padding\n",
    "            x1 += W + padding\n",
    "        y0 += H + padding\n",
    "        y1 += H + padding\n",
    "    return grid\n",
    "\n",
    "def conv2d(input, kernel_size, stride, num_filter, name = 'conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d(input, W, stride_shape, padding = 'SAME') + b\n",
    "\n",
    "def conv2d_transpose(input, kernel_size, stride, num_filter, name = 'conv2d_transpose'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape()[3]]\n",
    "        output_shape = tf.stack([tf.shape(input)[0], tf.shape(input)[1] * 2, tf.shape(input)[2] * 2, num_filter])\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d_transpose(input, W, output_shape, stride_shape, padding = 'SAME') + b\n",
    "\n",
    "def fc(input, num_output, name = 'fc'):\n",
    "    with tf.variable_scope(name):\n",
    "        num_input = input.get_shape()[1]\n",
    "        W = tf.get_variable('w', [num_input, num_output], tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [num_output], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.matmul(input, W) + b\n",
    "\n",
    "def batch_norm(input, is_training):\n",
    "    out = tf.contrib.layers.batch_norm(input, decay = 0.99, center = True, scale = True,\n",
    "                                       is_training = is_training, updates_collections = None)\n",
    "    return out\n",
    "\n",
    "def leaky_relu(input, alpha = 0.2):\n",
    "    return tf.maximum(alpha * input, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 1000\n",
    "        self.batch_size = 32\n",
    "        self.log_step = 50\n",
    "        self.visualize_step = 200\n",
    "        self.code_size = 100 #64\n",
    "        self.attr_size = 2\n",
    "        self.learning_rate = 2e-4\n",
    "        self.vis_learning_rate = 1e-2\n",
    "        self.recon_steps = 100\n",
    "        self.actmax_steps = 100\n",
    "        \n",
    "        self._dis_called = False\n",
    "        self._gen_called = False\n",
    "    \n",
    "        self.tracked_noise = np.random.normal(0, 1, [64, self.code_size])\n",
    "\n",
    "        self.real_input = tf.placeholder(tf.float32, [None, H_, W_, 3])\n",
    "        self.real_label = tf.placeholder(tf.float32, [None, 1])\n",
    "        self.fake_label = tf.placeholder(tf.float32, [None, 1])\n",
    "        self.noise = tf.placeholder(tf.float32, [None, self.code_size])\n",
    "        self.attr = tf.placeholder(tf.float32, [None, self.attr_size])\n",
    "        self.mismatch_attr = tf.placeholder(tf.float32, [None, self.attr_size])\n",
    "        \n",
    "        \n",
    "        self.is_train = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.recon_sample = tf.placeholder(tf.float32, [1, 32, 32, 3])\n",
    "        self.actmax_label = tf.placeholder(tf.float32, [1, 1])\n",
    "        \n",
    "        with tf.variable_scope('actmax'):\n",
    "            self.actmax_attr = tf.placeholder(tf.float32, [1, self.attr_size])\n",
    "#             tf.get_variable('actmax_code', [1, self.attr_size])\n",
    "            self.actmax_code = tf.get_variable('actmax_code', [1, self.code_size],\n",
    "                                               initializer = tf.constant_initializer(0.0))\n",
    "        \n",
    "        self._init_ops()\n",
    "\n",
    "    def _discriminator(self, inputs, attr_):\n",
    "        # We have multiple instances of the discriminator in the same computation graph,\n",
    "        # so set variable sharing if this is not the first invocation of this function.\n",
    "        with tf.variable_scope('dis', reuse = self._dis_called):\n",
    "            self._dis_called = True\n",
    "            print inputs\n",
    "            attr_ = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(attr_, 1), [1, 32, 1]), 1), [1, 32, 1, 1])\n",
    "            print \"attr_: {}\".format(attr_)\n",
    "            inputs = tf.concat([inputs, attr_], axis = 3)\n",
    "            print \"inputs: {}\".format(inputs)\n",
    "            dis_conv1 = conv2d(inputs, 4, 2, 32, 'conv1')\n",
    "#             print dis_conv1.shape\n",
    "            dis_lrelu1 = leaky_relu(dis_conv1)\n",
    "            dis_conv2 = conv2d(dis_lrelu1, 4, 2, 64, 'conv2')\n",
    "#             print dis_conv2.shape\n",
    "            dis_batchnorm2 = batch_norm(dis_conv2, self.is_train)\n",
    "            dis_lrelu2 = leaky_relu(dis_batchnorm2)\n",
    "            dis_conv3 = conv2d(dis_lrelu2, 4, 2, 128, 'conv3')\n",
    "#             print dis_conv3.shape\n",
    "            dis_batchnorm3 = batch_norm(dis_conv3, self.is_train)\n",
    "            dis_lrelu3 = leaky_relu(dis_batchnorm3)\n",
    "            dis_reshape3 = tf.reshape(dis_lrelu3, [-1, 4 * 4 * 128])\n",
    "#             print dis_reshape3.shape\n",
    "            # dis_addAttr3 = tf.concat([dis_reshape3, attr_], axis = 1)\n",
    "            dis_fc4 = fc(dis_reshape3, 1, 'fc4')\n",
    "            dis_prob = tf.nn.sigmoid(dis_fc4)\n",
    "            return tf.reduce_mean(dis_prob), dis_fc4\n",
    "\n",
    "    def _generator(self, noise, attr_):\n",
    "        with tf.variable_scope('gen', reuse = self._gen_called):\n",
    "            self._gen_called = True\n",
    "            inputs = tf.concat(values = [noise, attr_], axis = 1)\n",
    "            gen_fc1 = fc(inputs, 4 * 4 * 128, 'fc1')\n",
    "            gen_reshape1 = tf.reshape(gen_fc1, [-1, 4, 4, 128])\n",
    "#             print gen_reshape1.shape\n",
    "            gen_batchnorm1 = batch_norm(gen_reshape1, self.is_train)\n",
    "            gen_lrelu1 = leaky_relu(gen_batchnorm1)\n",
    "            gen_conv2 = conv2d_transpose(gen_lrelu1, 4, 2, 64, 'conv2')\n",
    "#             print gen_conv2.shape\n",
    "            gen_batchnorm2 = batch_norm(gen_conv2, self.is_train)\n",
    "            gen_lrelu2 = leaky_relu(gen_batchnorm2)\n",
    "            gen_conv3 = conv2d_transpose(gen_lrelu2, 4, 2, 32, 'conv3')\n",
    "#             print gen_conv3.shape\n",
    "            gen_batchnorm3 = batch_norm(gen_conv3, self.is_train)\n",
    "            gen_lrelu3 = leaky_relu(gen_batchnorm3)\n",
    "            gen_conv4 = conv2d_transpose(gen_lrelu3, 4, 2, 3, 'conv4')\n",
    "#             print gen_conv4.shape\n",
    "            gen_sigmoid4 = tf.sigmoid(gen_conv4)\n",
    "            return gen_sigmoid4\n",
    "\n",
    "    def _loss(self, labels, logits):\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits)\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    def _reconstruction_loss(self, generated, target):\n",
    "        loss = tf.nn.l2_loss(generated - target)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    # Define operations\n",
    "    def _init_ops(self):\n",
    "        \n",
    "        self.fake_samples_op = self._generator(self.noise, self.attr)\n",
    "        self.D_fake_prob, D_fake = self._discriminator(self.fake_samples_op, self.attr)\n",
    "        self.D_real_prob, D_real = self._discriminator(self.real_input, self.attr)\n",
    "        self.D_mis_prob, D_mismatch = self._discriminator(self.real_input, self.mismatch_attr)\n",
    "        \n",
    "        self.dis_loss_op = self._loss(self.real_label, D_real) + self._loss(self.fake_label, D_fake) + self._loss(self.fake_label, D_mismatch)\n",
    "        self.gen_loss_op = self._loss(self.real_label, D_fake)\n",
    "        \n",
    "        all_vars = tf.trainable_variables()\n",
    "\n",
    "        d_var = [v for v in all_vars if v.name.startswith('dis')]\n",
    "        g_var = [v for v in all_vars if v.name.startswith('gen')]\n",
    "        \n",
    "        # print the var status to check var\n",
    "        import tensorflow.contrib.slim as slim\n",
    "        print(\"********* d_var ********** \")\n",
    "        slim.model_analyzer.analyze_vars(d_var, print_info=True)\n",
    "        print(\"********* g_var ********** \") \n",
    "        slim.model_analyzer.analyze_vars(g_var, print_info=True)\n",
    "\n",
    "        dis_optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=0.5)\n",
    "        self.dis_train_op = dis_optimizer.minimize(self.dis_loss_op, var_list = d_var)\n",
    "        \n",
    "        gen_optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=0.5)\n",
    "        self.gen_train_op = gen_optimizer.minimize(self.gen_loss_op, var_list = g_var)\n",
    "        \n",
    "#         ##\n",
    "#         self.actmax_sample_op = self._generator(self.actmax_code, self.actmax_attr)\n",
    "#         actmax_dis = self._discriminator(self.actmax_sample_op, self.actmax_attr)\n",
    "#         self.actmax_loss_op = self._loss(self.actmax_label, actmax_dis)\n",
    "\n",
    "#         actmax_optimizer = tf.train.AdamOptimizer(self.vis_learning_rate)\n",
    "#         self.actmax_op = actmax_optimizer.minimize(self.actmax_loss_op, var_list = [self.actmax_code])\n",
    "        \n",
    "#         ##\n",
    "#         self.recon_loss_op = self._reconstruction_loss(self.actmax_sample_op, self.recon_sample)\n",
    "        \n",
    "#         recon_optimizer = tf.train.AdamOptimizer(self.vis_learning_rate)\n",
    "#         self.reconstruct_op = recon_optimizer.minimize(self.recon_loss_op, var_list = [self.actmax_code])\n",
    "    \n",
    "    # Training function\n",
    "    def train(self, sess, train_samples, sample_features):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        train_data, train_attr= train_samples\n",
    "        num_train = train_data.shape[0]\n",
    "        step = 0\n",
    "        \n",
    "        # smooth the loss curve so that it does not fluctuate too much\n",
    "        smooth_factor = 0.95\n",
    "        plot_dis_s = 0\n",
    "        plot_gen_s = 0\n",
    "        plot_ws = 0\n",
    "        \n",
    "        plot_dis_f = 0\n",
    "        plot_dis_r = 0\n",
    "        plot_dis_m = 0\n",
    "        \n",
    "        dis_losses = []\n",
    "        fakes = []\n",
    "        reals = []\n",
    "        mismatchs = []\n",
    "        gen_losses = []\n",
    "        \n",
    "        import copy\n",
    "        update_ratio = 2\n",
    "        gen_loss = 0.0\n",
    "        dis_loss = 0.0\n",
    "        for epoch in range(self.num_epoch):\n",
    "            for i in range(num_train // self.batch_size):\n",
    "                step += 1\n",
    "\n",
    "                batch_data = train_data[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "                batch_attr = train_attr[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "                noise = np.random.normal(0, 1, [self.batch_size, self.code_size])\n",
    "                zeros = np.zeros([self.batch_size, 1])\n",
    "                ones = np.ones([self.batch_size, 1])\n",
    "                mismatch_attr = copy.deepcopy(batch_attr)\n",
    "                for i in range(len(mismatch_attr)):\n",
    "                    for j in range(len(mismatch_attr[i])):\n",
    "                        \"\"\"\n",
    "                        if i == 0:\n",
    "                            print(\"before\")\n",
    "                            print(mismatch_attr[i][j])\n",
    "                            print(batch_attr[i][j])\n",
    "                        \"\"\"\n",
    "                        if mismatch_attr[i][j] == 0:\n",
    "                            mismatch_attr[i][j] = 1\n",
    "                        else:\n",
    "                            mismatch_attr[i][j] = 0\n",
    "                        \"\"\"\n",
    "                        if i == 0:\n",
    "                            print(\"after\")\n",
    "                            print(mismatch_attr[i][j])\n",
    "                            print(batch_attr[i][j])\n",
    "                        \"\"\"\n",
    "                # print \"attr shape: {} {}\".format(batch_attr.shape, mismatch_attr.shape)\n",
    "                if batch_attr.shape[0] != self.batch_size:\n",
    "                    print \"Error: attr shape not match: attr shape {}, batch size {}\".format(batch_attr.shape, self.batch_size)\n",
    "                    continue\n",
    "                dis_feed_dict = {self.real_input: batch_data, \n",
    "                                 self.noise: noise, \n",
    "                                 self.attr: batch_attr,\n",
    "                                 self.mismatch_attr: mismatch_attr,\n",
    "                                 self.real_label: ones, \n",
    "                                 self.fake_label: zeros, \n",
    "                                 self.is_train:True}\n",
    "                \n",
    "                gen_feed_dict = {self.noise: noise, \n",
    "                                 self.attr: batch_attr,\n",
    "                                 self.real_label: ones, \n",
    "                                 self.is_train: True}\n",
    "                \"\"\"\n",
    "                if i % update_ratio == 0:\n",
    "                    _, dis_loss = sess.run([self.dis_train_op, self.dis_loss_op], feed_dict = dis_feed_dict)\n",
    "                else:\n",
    "                    _, gen_loss = sess.run([self.gen_train_op, self.gen_loss_op], feed_dict = gen_feed_dict)\n",
    "                \"\"\"\n",
    "                _, dis_loss, dis_fake, dis_real, dis_mis = sess.run([self.dis_train_op, self.dis_loss_op, self.D_fake_prob,\n",
    "                                                                    self.D_real_prob, self.D_mis_prob], feed_dict = dis_feed_dict)\n",
    "                _, gen_loss = sess.run([self.gen_train_op, self.gen_loss_op], feed_dict = gen_feed_dict)\n",
    "\n",
    "                plot_dis_s = plot_dis_s * smooth_factor + dis_loss * (1 - smooth_factor)\n",
    "                plot_gen_s = plot_gen_s * smooth_factor + gen_loss * (1 - smooth_factor)\n",
    "                plot_ws = plot_ws * smooth_factor + (1 - smooth_factor)\n",
    "                dis_losses.append(plot_dis_s / plot_ws)\n",
    "                gen_losses.append(plot_gen_s / plot_ws)\n",
    "                \n",
    "                plot_dis_f = plot_dis_f * smooth_factor + dis_fake * (1 - smooth_factor)\n",
    "                plot_dis_r = plot_dis_r * smooth_factor + dis_real * (1 - smooth_factor)\n",
    "                plot_dis_m = plot_dis_m * smooth_factor + dis_mis * (1 - smooth_factor)\n",
    "                fakes.append(plot_dis_f / plot_ws)\n",
    "                reals.append(plot_dis_r / plot_ws)\n",
    "                mismatchs.append(plot_dis_m / plot_ws)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('Iteration {0}: dis loss = {1:.4f}, gen loss = {2:.4f}'.format(step, dis_loss, gen_loss))\n",
    "\n",
    "            if not os.path.exists(OUTPUT_DIR):\n",
    "                os.mkdir(OUTPUT_DIR)\n",
    "                \n",
    "            filename = OUTPUT_DIR + '%d_%d.png' % (epoch,i)\n",
    "            \n",
    "            fig = plt.figure(figsize = (8, 8)) \n",
    "            ax1 = plt.subplot(111)\n",
    "            image = viz_grid(self.generate(self.tracked_noise, sample_features), 1)\n",
    "            scipy.misc.imsave(filename, image)\n",
    "            ax1.imshow(image)\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(dis_losses)\n",
    "            plt.title('discriminator loss')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.plot(fakes, label=\"fake\", color=\"blue\")\n",
    "            plt.plot(reals, label=\"real\", color=\"red\")\n",
    "            plt.plot(mismatchs, label=\"mismatch\", color=\"green\")\n",
    "            plt.legend(['fake', 'real', 'mismatch'], loc='upper left')\n",
    "            plt.title('D_fake_real_mis')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('prob')\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(gen_losses)\n",
    "            plt.title('generator loss')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "            \n",
    "            dis_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'dis')\n",
    "            gen_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'gen')\n",
    "            saver = tf.train.Saver(dis_var_list + gen_var_list)\n",
    "            saver.save(sess, 'model/dcgan_%d' % epoch)\n",
    "\n",
    "    # Find the reconstruction of one input sample\n",
    "    def reconstruct_one_sample(self, sample):\n",
    "        ##\n",
    "        code = np.random.random([1, self.code_size])\n",
    "        actmax_init_val = tf.convert_to_tensor(code, dtype = tf.float32)\n",
    "        \n",
    "        sess.run(self.actmax_code.assign(actmax_init_val))\n",
    "        last_reconstruction = None\n",
    "        last_loss = None\n",
    "        for i in range(self.recon_steps):\n",
    "        \n",
    "            ##\n",
    "            recon_feed_dict = {self.recon_sample: sample, \n",
    "                               self.is_train: False}\n",
    "            \n",
    "            run_ops = [self.recon_loss_op, self.reconstruct_op, self.actmax_sample_op]\n",
    "            last_loss, _, last_reconstruction = sess.run(run_ops, feed_dict = recon_feed_dict)\n",
    "        return last_loss, last_reconstruction\n",
    "\n",
    "    # Find the reconstruction of a batch of samples\n",
    "    def reconstruct(self, samples):\n",
    "        reconstructions = np.zeros(samples.shape)\n",
    "        total_loss = 0\n",
    "        for i in range(samples.shape[0]):\n",
    "            loss, reconstructions[i:i+1] = self.reconstruct_one_sample(samples[i:i+1])\n",
    "            total_loss += loss\n",
    "        return total_loss / samples.shape[0], reconstructions\n",
    "\n",
    "    # Generates a single sample from input code\n",
    "    def generate_one_sample(self, code, attr_):\n",
    "\n",
    "        gen_vis_feed_dict = {self.noise: code, \n",
    "                             self.attr: attr_, \n",
    "                             self.is_train: False}\n",
    "        \n",
    "        generated = sess.run(self.fake_samples_op, feed_dict = gen_vis_feed_dict)\n",
    "        return generated\n",
    "\n",
    "    # Generates samples from input batch of codes\n",
    "    def generate(self, codes, attr_):\n",
    "        generated = np.zeros((codes.shape[0], H_, W_, 3))\n",
    "        for i in range(codes.shape[0]):\n",
    "            generated[i:i+1] = self.generate_one_sample(codes[i:i+1], attr_)\n",
    "        return generated\n",
    "\n",
    "    # Perform activation maximization on one initial code\n",
    "    def actmax_one_sample(self, initial_code):\n",
    "        \n",
    "        ##\n",
    "        actmax_init_val = tf.convert_to_tensor(initial_code, dtype = tf.float32)\n",
    "        sess.run(self.actmax_code.assign(actmax_init_val))\n",
    "        for i in range(self.actmax_steps):\n",
    "            actmax_feed_dict = {\n",
    "                self.actmax_label: np.ones([1, 1]),\n",
    "                self.is_train: False\n",
    "            }\n",
    "            _, last_actmax = sess.run([self.actmax_op, self.actmax_sample_op], feed_dict = actmax_feed_dict)\n",
    "        return last_actmax\n",
    "\n",
    "    # Perform activation maximization on a batch of different initial codes\n",
    "    def actmax(self, initial_codes):\n",
    "        actmax_results = np.zeros((initial_codes.shape[0], 32, 32, 3))\n",
    "        for i in range(initial_codes.shape[0]):\n",
    "            actmax_results[i:i+1] = self.actmax_one_sample(initial_codes[i:i+1])\n",
    "        return actmax_results.clip(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "* start to train\n",
    "* save the trained model at 'model/dcgan' \n",
    "* save output image & loss curve at OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gen/Sigmoid:0\", shape=(?, ?, ?, 3), dtype=float32, device=/device:CPU:0)\n",
      "attr_: Tensor(\"dis/Tile_1:0\", shape=(?, 32, 32, 2), dtype=float32, device=/device:CPU:0)\n",
      "inputs: Tensor(\"dis/concat:0\", shape=(?, 32, 32, 5), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "attr_: Tensor(\"dis_1/Tile_1:0\", shape=(?, 32, 32, 2), dtype=float32, device=/device:CPU:0)\n",
      "inputs: Tensor(\"dis_1/concat:0\", shape=(?, 32, 32, 5), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "attr_: Tensor(\"dis_2/Tile_1:0\", shape=(?, 32, 32, 2), dtype=float32, device=/device:CPU:0)\n",
      "inputs: Tensor(\"dis_2/concat:0\", shape=(?, 32, 32, 5), dtype=float32, device=/device:CPU:0)\n",
      "********* d_var ********** "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        dcgan = DCGAN()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        dcgan.train(sess, train_samples, sample_features)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
